{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Дисциплина «Искусственный интеллект»"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Рабочая тетрадь №7"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1.1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8151036049051821\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np. exp(-x))\n",
    "\n",
    "class Neuron:\n",
    "    def __init__ (self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "    def feedforward(self, inputs):\n",
    "        total = np.dot(self.weights, inputs) + self.bias\n",
    "        return sigmoid(total)\n",
    "    \n",
    "class OurNeuralNetwork:\n",
    "    def __init__(self):\n",
    "        weights = np.array([0.5, 0.5, 0.5])\n",
    "        bias = 0\n",
    "        self.h1 = Neuron(weights, bias)\n",
    "        self.h2 = Neuron(weights, bias)\n",
    "        self.h3 = Neuron(weights, bias)\n",
    "        self.o1 = Neuron(weights, bias)\n",
    "\n",
    "    def feedforward(self, x):\n",
    "        out_h1 = self.h1.feedforward(x)\n",
    "        out_h2 = self.h2.feedforward(x)\n",
    "        out_h3 = self.h3.feedforward(x)\n",
    "        out_o1 = self.o1.feedforward(np.array([out_h1, out_h2, out_h3]))\n",
    "        return out_o1\n",
    "\n",
    "\n",
    "network = OurNeuralNetwork ()\n",
    "x = np.array ([2, 3, 4])\n",
    "print(network.feedforward(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8757270529783324, 0.8757270529783324)\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np. exp(-x))\n",
    "\n",
    "class Neuron:\n",
    "    def __init__ (self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "    def feedforward(self, inputs):\n",
    "        total = np.dot(self.weights, inputs) + self.bias\n",
    "        return sigmoid(total)\n",
    "    \n",
    "class OurNeuralNetwork:\n",
    "    def __init__(self):\n",
    "        weights = np.array([1, 0])\n",
    "        bias = 1\n",
    "        self.h1 = Neuron(weights, bias)\n",
    "        self.h2 = Neuron(weights, bias)\n",
    "        self.o1 = Neuron(weights, bias)\n",
    "        self.o2 = Neuron(weights, bias)\n",
    "\n",
    "    def feedforward(self, x):\n",
    "        out_h1 = self.h1.feedforward(x)\n",
    "        out_h2 = self.h2.feedforward(x)\n",
    "        out_o1 = self.o1.feedforward(np.array([out_h1, out_h2]))\n",
    "        out_o2 = self.o2.feedforward(np.array([out_h1, out_h2]))\n",
    "        return out_o1, out_o2\n",
    "\n",
    "\n",
    "network = OurNeuralNetwork ()\n",
    "x = np.array ([2, 3])\n",
    "print(network.feedforward(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1.1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def tanh(x):\n",
    "    return math.tanh(x)\n",
    "\n",
    "def ReLU(x):\n",
    "    return max(0, x)\n",
    "\n",
    "class Neuron:\n",
    "    def __init__ (self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "    def feedforward(self, inputs):\n",
    "        total = np.dot(self.weights, inputs) + self.bias\n",
    "        return sigmoid(total) ###\n",
    "    \n",
    "class OurNeuralNetwork:\n",
    "    def __init__(self):\n",
    "        weights = np.array([0.5, 0.5, 0.5])\n",
    "        bias = 0\n",
    "        self.h1 = Neuron(weights, bias)\n",
    "        self.h2 = Neuron(weights, bias)\n",
    "        self.h3 = Neuron(weights, bias)\n",
    "        self.o1 = Neuron(weights, bias)\n",
    "\n",
    "    def feedforward(self, x):\n",
    "        out_h1 = self.h1.feedforward(x)\n",
    "        out_h2 = self.h2.feedforward(x)\n",
    "        out_h3 = self.h3.feedforward(x)\n",
    "        out_o1 = self.o1.feedforward(np.array([out_h1, out_h2, out_h3]))\n",
    "        return out_o1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m x \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39miloc[:, :\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mvalues\n\u001b[1;32m      4\u001b[0m y \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39miloc[:, \u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mvalues\n\u001b[0;32m----> 6\u001b[0m x_train, x_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(x, y, test_size\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m, random_state\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, stratify\u001b[39m=\u001b[39;49my)\n\u001b[1;32m      8\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTrain/Test Sizes : \u001b[39m\u001b[39m'\u001b[39m, x_train\u001b[39m.\u001b[39mshape, x_test\u001b[39m.\u001b[39mshape, y_train\u001b[39m.\u001b[39mshape, y_test\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     10\u001b[0m mlp_classifier \u001b[39m=\u001b[39m MLPClassifier(random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_split.py:2583\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2579\u001b[0m         CVClass \u001b[39m=\u001b[39m ShuffleSplit\n\u001b[1;32m   2581\u001b[0m     cv \u001b[39m=\u001b[39m CVClass(test_size\u001b[39m=\u001b[39mn_test, train_size\u001b[39m=\u001b[39mn_train, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m-> 2583\u001b[0m     train, test \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(cv\u001b[39m.\u001b[39msplit(X\u001b[39m=\u001b[39marrays[\u001b[39m0\u001b[39m], y\u001b[39m=\u001b[39mstratify))\n\u001b[1;32m   2585\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(\n\u001b[1;32m   2586\u001b[0m     chain\u001b[39m.\u001b[39mfrom_iterable(\n\u001b[1;32m   2587\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m arrays\n\u001b[1;32m   2588\u001b[0m     )\n\u001b[1;32m   2589\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_split.py:1689\u001b[0m, in \u001b[0;36mBaseShuffleSplit.split\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1659\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[1;32m   1660\u001b[0m \n\u001b[1;32m   1661\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1686\u001b[0m \u001b[39mto an integer.\u001b[39;00m\n\u001b[1;32m   1687\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1688\u001b[0m X, y, groups \u001b[39m=\u001b[39m indexable(X, y, groups)\n\u001b[0;32m-> 1689\u001b[0m \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter_indices(X, y, groups):\n\u001b[1;32m   1690\u001b[0m     \u001b[39myield\u001b[39;00m train, test\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_split.py:2078\u001b[0m, in \u001b[0;36mStratifiedShuffleSplit._iter_indices\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   2076\u001b[0m class_counts \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mbincount(y_indices)\n\u001b[1;32m   2077\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mmin(class_counts) \u001b[39m<\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m-> 2078\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2079\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe least populated class in y has only 1\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2080\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m member, which is too few. The minimum\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2081\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m number of groups for any class cannot\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2082\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m be less than 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2083\u001b[0m     )\n\u001b[1;32m   2085\u001b[0m \u001b[39mif\u001b[39;00m n_train \u001b[39m<\u001b[39m n_classes:\n\u001b[1;32m   2086\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2087\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe train_size = \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m should be greater or \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2088\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mequal to the number of classes = \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (n_train, n_classes)\n\u001b[1;32m   2089\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('iris.csv')\n",
    "\n",
    "x = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, 1].values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0, stratify=y)\n",
    "\n",
    "print('Train/Test Sizes : ', x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "mlp_classifier = MLPClassifier(random_state=0)\n",
    "mlp_classifier.fit(x_train, y_train)\n",
    "\n",
    "y_preds = mlp_classifier.predict(x_train, y_train)\n",
    "\n",
    "print('Test Accuracy: %.3f'%mlp_classifier.score(x_test, y_test))\n",
    "print('Training Accuracy: %.3f'%mlp_classifier.score(x_train, y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MLPClassifier' object has no attribute 'n_layers_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m):\n\u001b[1;32m     10\u001b[0m             plt\u001b[39m.\u001b[39mtext(i\u001b[39m-\u001b[39m\u001b[39m0.2\u001b[39m, j\u001b[39m+\u001b[39m\u001b[39m0.1\u001b[39m, \u001b[39mstr\u001b[39m(conf_mat[j, i]), color\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtab:red\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m plot_confusion_matrix(y_test, mlp_classifier\u001b[39m.\u001b[39;49mpredict(x_test))\n\u001b[1;32m     14\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mLoss: \u001b[39m\u001b[39m\"\u001b[39m , mlp_classifier\u001b[39m.\u001b[39mloss_)\n\u001b[1;32m     15\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNumber of Coefs : \u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mlen\u001b[39m(mlp_classifier\u001b[39m.\u001b[39mcoefs_))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1154\u001b[0m, in \u001b[0;36mMLPClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1141\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Predict using the multi-layer perceptron classifier.\u001b[39;00m\n\u001b[1;32m   1142\u001b[0m \n\u001b[1;32m   1143\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[39m    The predicted classes.\u001b[39;00m\n\u001b[1;32m   1152\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1153\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m-> 1154\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predict(X)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1158\u001b[0m, in \u001b[0;36mMLPClassifier._predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m   1156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_predict\u001b[39m(\u001b[39mself\u001b[39m, X, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m   1157\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Private predict method with optional input validation\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1158\u001b[0m     y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_pass_fast(X, check_input\u001b[39m=\u001b[39;49mcheck_input)\n\u001b[1;32m   1160\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1161\u001b[0m         y_pred \u001b[39m=\u001b[39m y_pred\u001b[39m.\u001b[39mravel()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:209\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._forward_pass_fast\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[39m# Forward propagate\u001b[39;00m\n\u001b[1;32m    208\u001b[0m hidden_activation \u001b[39m=\u001b[39m ACTIVATIONS[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation]\n\u001b[0;32m--> 209\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_layers_ \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m    210\u001b[0m     activation \u001b[39m=\u001b[39m safe_sparse_dot(activation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoefs_[i])\n\u001b[1;32m    211\u001b[0m     activation \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercepts_[i]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MLPClassifier' object has no attribute 'n_layers_'"
     ]
    }
   ],
   "source": [
    "def plot_confusion_matrix(V_test, Y_preds) :\n",
    "    conf_mat = confusion_matrix(V_test, Y_preds)\n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    plt.matshow(conf_mat, cmap=plt.cm.Blues, fignum=1) \n",
    "    plt.yticks(range(10), range(10))\n",
    "    plt.xticks(range(10), range (10)) \n",
    "    plt.colorbar (); \n",
    "    for i in range (10):\n",
    "        for j in range(10):\n",
    "            plt.text(i-0.2, j+0.1, str(conf_mat[j, i]), color='tab:red')\n",
    "            \n",
    "plot_confusion_matrix(y_test, mlp_classifier.predict(x_test))\n",
    "\n",
    "print(\"Loss: \" , mlp_classifier.loss_)\n",
    "print(\"Number of Coefs : \", len(mlp_classifier.coefs_))\n",
    "print(\"Number of Intercepts: \", len(mlp_classifier.intercepts_))\n",
    "print(\"Number of Iterations for Which Estimator Ran :\", mlp_classifier.n_iter_)\n",
    "print(\"Name of Output Laver Activation Function :\", mlp_classifier.out_activation_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m mlp_regressor\u001b[39m.\u001b[39mfit(x_train, y_train)\n\u001b[1;32m      4\u001b[0m Y_preds \u001b[39m=\u001b[39m mlp_regressor\u001b[39m.\u001b[39mpredict (x_test)\n\u001b[0;32m----> 5\u001b[0m \u001b[39mprint\u001b[39m(y_preds[:\u001b[39m10\u001b[39m])\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(y_test[:\u001b[39m10\u001b[39m])\n\u001b[1;32m      8\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTest R^2 Score : \u001b[39m\u001b[39m%.3f\u001b[39;00m\u001b[39m*\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%\u001b[39mmlp_regressor\u001b[39m.\u001b[39mscore(x_test, y_test))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_preds' is not defined"
     ]
    }
   ],
   "source": [
    "mlp_regressor = MLPRegressor(random_state=42)\n",
    "mlp_regressor.fit(x_train, y_train)\n",
    "\n",
    "Y_preds = mlp_regressor.predict (x_test)\n",
    "print(y_preds[:10])\n",
    "print(y_test[:10])\n",
    "\n",
    "print('Test R^2 Score : %.3f*'%mlp_regressor.score(x_test, y_test))\n",
    "print('Training R^2 Score : %.3f*'%mlp_regressor.score(x_train, y_train))\n",
    "\n",
    "print('Loss: ', mlp_regressor.loss_)\n",
    "print(\"Number of Coefs : \", len(mlp_regressor.coefs_))\n",
    "print(\"Number of Iterations for Which Estimator Ran :\", mlp_regressor.n_iter_)\n",
    "print(\"Name of Output Laver Activation Function :\", mlp_regressor.out_activation_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
